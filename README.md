This project explores the development and application of Repulsive Mixture Models (RMMs) within the Bayesian framework to address key challenges in mixture modelling, such as overfitting, label switching and excessive model complexity. Traditional mixture models often suffer from overlapping clusters and redundant components, which reduce interpretability and model performance. To mitigate these issues, this project introduces repulsion mechanisms using determinantal point processes (DPPs) and Gibbs measures to enforce separation between mixture components.

A significant part of this work involves implementing Reversible Jump Markov Chain Monte Carlo (RJ-MCMC) for trans-dimensional inference, allowing the model to efficiently infer the optimal number of mixture components while incorporating repulsion constraints. The performance of Bayesian Repulsive Gaussian Mixture Models (BRGMMs) is evaluated through extensive simulation studies and real-world datasets, comparing their effectiveness to standard mixture models.

By integrating repulsion into Bayesian mixture models, this project aims to enhance model interpretability, reduce overfitting, and provide a more robust framework for clustering and density estimation in complex data environments.
